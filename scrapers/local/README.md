# Scrapers Locais (Sem Proxy)

VersÃ£o alternativa dos scrapers que **nÃ£o usa proxy**, ideal para execuÃ§Ã£o local usando sua conexÃ£o de internet normal.

## ğŸ¯ Objetivo

- Coletar odds das casas de apostas usando sua internet local (sem proxy)
- Enviar dados diretamente para a API no Railway
- Mais simples e rÃ¡pido para desenvolvimento/teste

## ğŸ“‹ PrÃ©-requisitos

```bash
# Instalar dependÃªncias
pip install playwright requests python-dotenv

# Instalar browser do Playwright
playwright install chromium
```

## âš™ï¸ ConfiguraÃ§Ã£o

1. **Configure o .env.local:**

```env
# URL da API no Railway (obrigatÃ³rio)
API_URL=https://seu-projeto.up.railway.app/api/odds/scraper

# Database (apenas se precisar consultar dados localmente)
DATABASE_URL=postgresql+psycopg://...

# Log
LOG_LEVEL=INFO
```

2. **Verifique se a API Railway estÃ¡ acessÃ­vel:**

```bash
curl https://seu-projeto.up.railway.app/health
```

## ğŸš€ Uso

### Rodar Todos os Scrapers

```bash
# Usando o script bash
chmod +x run_local_scraper.sh
./run_local_scraper.sh

# Ou diretamente com Python
python scrapers/local/run_all_local.py

# No Windows (PowerShell)
python scrapers\local\run_all_local.py
```

### Rodar Scraper Individual

```python
from scrapers.local.betano_local import collect_betano_local
from scrapers.shared.sender import send_odds_to_api

# Coleta dados
data = collect_betano_local()

# Envia para API
if data:
    send_odds_to_api(data)
```

## ğŸ“Š Scrapers DisponÃ­veis

| Casa | Status | Obs |
|------|--------|-----|
| Betano | âœ… Funcional | Double Chance |
| Esportes da Sorte | âœ… Funcional | Double Chance |
| Superbet | âš ï¸ Em desenvolvimento | Parser pendente |
| Bet365 | âš ï¸ Em desenvolvimento | Parser pendente |

## ğŸ” Como Funciona

1. **Browser Local**: Usa Playwright com configuraÃ§Ã£o simples, sem proxy
2. **Coleta**: Cada scraper acessa o site e extrai as odds
3. **Formato**: Converte para o formato padrÃ£o da API
4. **Envio**: Posta os dados para `API_URL/api/odds/scraper`
5. **API**: Processa e salva no banco PostgreSQL no Railway

## ğŸ†š DiferenÃ§as vs VersÃ£o com Proxy

| Aspecto | VersÃ£o Local | VersÃ£o com Proxy |
|---------|-------------|------------------|
| Internet | Sua conexÃ£o | Proxy residencial |
| Velocidade | Mais rÃ¡pida | Pode ser mais lenta |
| Bloqueios | PossÃ­vel | Menos provÃ¡vel |
| Custo | GrÃ¡tis | Pago (Webshare) |
| Uso | Desenvolvimento/teste | ProduÃ§Ã£o |

## âš ï¸ LimitaÃ§Ãµes

- **Bloqueios**: Sites podem bloquear seu IP se fizer muitas requisiÃ§Ãµes
- **GeolocalizaÃ§Ã£o**: Alguns sites podem exigir IP brasileiro
- **Rate Limiting**: Sem rotaÃ§Ã£o de IP, pode atingir limites mais rÃ¡pido

## ğŸ’¡ Dicas

1. **Execute com moderaÃ§Ã£o**: NÃ£o rode muito frequentemente para evitar bloqueios
2. **Use VPN brasileira**: Se estiver fora do Brasil
3. **HorÃ¡rios**: Rode em horÃ¡rios de menor trÃ¡fego (2h-6h AM)
4. **Monitore**: Acompanhe os logs para detectar bloqueios

## ğŸ› Troubleshooting

### "Timeout" ao acessar sites

```python
# Aumente o timeout no collector
page.goto(URL, timeout=120000)  # 2 minutos
```

### "403 Forbidden"

Seu IP pode estar bloqueado. SoluÃ§Ãµes:
- Aguarde algumas horas
- Use VPN
- Mude para versÃ£o com proxy

### Dados nÃ£o chegam na API

1. Verifique `API_URL` no `.env.local`
2. Teste manualmente:
```bash
curl -X POST $API_URL \
  -H "Content-Type: application/json" \
  -d '{"data": []}'
```

## ğŸ“ Logs

Os logs mostram o progresso:

```
ğŸ  INICIANDO COLETA LOCAL (SEM PROXY)
ğŸ“Š [1/4] BETANO
ğŸ‡§ğŸ‡· Iniciando coleta BETANO (conexÃ£o local)
âœ… PÃ¡gina carregada com sucesso
âœ… Encontrados 8 jogos na Betano
âœ… Betano: 8 jogos coletados e enviados
```

## ğŸ”„ AutomaÃ§Ã£o com Cron

Para rodar automaticamente no Linux/Mac:

```bash
# Edite o crontab
crontab -e

# Execute a cada 6 horas
0 */6 * * * cd /caminho/leite-bets && ./run_local_scraper.sh >> /var/log/scraper.log 2>&1
```

### AutomaÃ§Ã£o no Windows com Task Scheduler

```powershell
# Crie um script .bat
@echo off
cd C:\caminho\leite-bets
python scrapers\local\run_all_local.py >> logs\scraper.log 2>&1
```

## ğŸ“¦ Estrutura de Arquivos

```
scrapers/local/
â”œâ”€â”€ README.md                    # Este arquivo
â”œâ”€â”€ __init__.py                  # MÃ³dulo Python
â”œâ”€â”€ browser_no_proxy.py          # Browser sem proxy
â”œâ”€â”€ betano_local.py              # Scraper Betano
â”œâ”€â”€ superbet_local.py            # Scraper Superbet
â”œâ”€â”€ esportesdasorte_local.py     # Scraper Esportes
â”œâ”€â”€ bet365_local.py              # Scraper Bet365
â””â”€â”€ run_all_local.py             # Executa todos
```

## ğŸ” SeguranÃ§a

- Nunca commite o `.env.local` com credenciais reais
- Use variÃ¡veis de ambiente para dados sensÃ­veis
- NÃ£o exponha logs com informaÃ§Ãµes sensÃ­veis

## ğŸ“Š Monitoramento

Para monitorar a execuÃ§Ã£o:

```bash
# Ver logs em tempo real
tail -f logs/scraper.log

# Contar execuÃ§Ãµes bem-sucedidas
grep "âœ…" logs/scraper.log | wc -l
```

## ğŸš€ PrÃ³ximos Passos

1. Implementar parsers completos para Superbet e Bet365
2. Adicionar retry automÃ¡tico em caso de falha
3. Implementar cache local para evitar requisiÃ§Ãµes duplicadas
4. Adicionar notificaÃ§Ãµes quando houver erros
5. Criar dashboard local para visualizar status

## ğŸ“ Suporte

Para problemas ou dÃºvidas:
1. Verifique os logs detalhados
2. Revise a configuraÃ§Ã£o do `.env.local`
3. Teste cada scraper individualmente
4. Abra uma issue no repositÃ³rio
