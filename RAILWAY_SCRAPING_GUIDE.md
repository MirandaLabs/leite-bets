# ğŸš€ Guia Definitivo - Executar Raspagem no Railway

## ğŸ“ VisÃ£o Geral da Arquitetura

Seu projeto tem **2 APIs separadas**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BACKEND API (Railway)              â”‚
â”‚  Port 8000 - FastAPI                â”‚
â”‚  - Recebe odds do scraper           â”‚
â”‚  - Calcula arbitragem               â”‚
â”‚  - POST /api/odds/update            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘
         â”‚ (dados)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCRAPER API (Local/Docker)         â”‚
â”‚  Port 8001 - FastAPI                â”‚
â”‚  - Coleta dados dos sites           â”‚
â”‚  - POST /scrape/betano              â”‚
â”‚  - POST /scrape/bet365              â”‚
â”‚  - POST /scrape/superbet            â”‚
â”‚  - POST /scrape/esportesdasorte     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… OPÃ‡ÃƒO 1: Trigger via N8N (RECOMENDADO)

A forma **mais segura** e **melhor para produÃ§Ã£o** no Railway.

### âš™ï¸ Setup

1. **Adicione um novo endpoint no Backend** (`backend/main.py`):

```python
from fastapi import BackgroundTasks
from datetime import datetime
import httpx
import asyncio

# ConfiguraÃ§Ã£o - adicione ao topo do arquivo
SCRAPER_API_URL = os.getenv("SCRAPER_API_URL", "http://localhost:8001")

@app.post("/api/trigger/all")
async def trigger_all_scrapers(background_tasks: BackgroundTasks):
    """
    Trigger para todos os scrapers (chamado pelo N8N)
    """
    background_tasks.add_task(run_all_scrapers)
    
    return {
        "status": "triggered",
        "message": "Scrapers iniciados em background",
        "timestamp": datetime.utcnow().isoformat()
    }

async def run_all_scrapers():
    """Executa todos os scrapers sequencialmente"""
    results = {}
    
    scrapers = ["betano", "bet365", "superbet", "esportesdasorte"]
    
    async with httpx.AsyncClient(timeout=300.0) as client:
        for scraper in scrapers:
            try:
                print(f"ğŸ”„ Triggering {scraper}...")
                response = await client.post(
                    f"{SCRAPER_API_URL}/scrape/{scraper}"
                )
                results[scraper] = {
                    "status": "success" if response.status_code == 200 else "error",
                    "items": len(response.json().get("data", []))
                }
                print(f"âœ… {scraper} completed: {results[scraper]}")
            except Exception as e:
                print(f"âŒ {scraper} failed: {str(e)}")
                results[scraper] = {"status": "error", "error": str(e)}
    
    return results
```

2. **Configure variÃ¡vel no Railway**:

```env
SCRAPER_API_URL=https://seu-scraper-railway.railway.app
```

3. **Configure no N8N**:

```
Schedule Trigger (a cada 30 min)
    â†“
HTTP Request (POST)
    â†“
URL: https://seu-backend-railway.railway.app/api/trigger/all
Method: POST
Headers: Content-Type: application/json
```

### âœ… Vantagens
- âœ… NÃ£o bloqueia requisiÃ§Ã£o (background tasks)
- âœ… Melhor tratamento de erros
- âœ… Logs centralizados
- âœ… Escala bem em produÃ§Ã£o
- âœ… Pode ser agendado

---

## ğŸ”„ OPÃ‡ÃƒO 2: Trigger Direto do N8N para Scraper

Se vocÃª quer **executar o scraper diretamente** (mais rÃ¡pido, menos seguro).

### âš™ï¸ Setup

**No N8N, use este endpoint:**

```
POST https://seu-scraper-railway.railway.app/scrape/betano
POST https://seu-scraper-railway.railway.app/scrape/bet365
POST https://seu-scraper-railway.railway.app/scrape/superbet
POST https://seu-scraper-railway.railway.app/scrape/esportesdasorte
```

### Workflow N8N:
```
Schedule Trigger
    â†“
HTTP Request â†’ /scrape/betano
    â†“
IF (status === 200)
    â†“
Parse JSON
    â†“
Loop through items
    â†“
HTTP Request â†’ Backend /api/odds/update
```

### âš ï¸ Desvantagens
- âŒ Timeout apÃ³s 30s (requisiÃ§Ãµes podem falhar)
- âŒ Precisa de retry logic mais complexa
- âŒ Mais difÃ­cil de debugar

---

## ğŸ¯ OPÃ‡ÃƒO 3: Trigger Manual via cURL (Testes)

Para **testar rapidamente** ou **debug**:

```bash
# Trigger todos os scrapers via Backend
curl -X POST https://seu-backend-railway.railway.app/api/trigger/all

# Trigger scraper especÃ­fico direto
curl -X POST https://seu-scraper-railway.railway.app/scrape/betano

# Verificar status do backend
curl https://seu-backend-railway.railway.app/health

# Verificar status do scraper
curl https://seu-scraper-railway.railway.app/health
```

---

## ğŸ“‹ Checklist para Railway

### Backend Service

```env
DATABASE_URL=postgresql://user:pass@host:port/db
TELEGRAM_BOT_TOKEN=seu_token
SCRAPER_API_URL=https://seu-scraper-railway.railway.app
```

**Entrypoint:**
```bash
sh ./backend/entrypoint-railway.sh
```

### Scraper Service

```env
# VariÃ¡veis do proxy (opcional)
IP_1=xxx
IP_2=xxx
# ... atÃ© IP_10

# Para logging
LOG_LEVEL=info
```

**Entrypoint:**
```bash
python -m scrapers.api.main
```

Ou via uvicorn:
```bash
uvicorn scrapers.api.main:app --host 0.0.0.0 --port 8000
```

---

## ğŸ”— Fluxo Completo no Railway

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   N8N       â”‚ (Cron job a cada 30min)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€â”€â†’ POST /api/trigger/all
            â”‚
       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Backend (Railway)           â”‚
       â”‚   â”œâ”€ DB: PostgreSQL           â”‚
       â”‚   â”œâ”€ Bot: Telegram            â”‚
       â”‚   â””â”€ Port: 8000               â”‚
       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ (faz request para)
            â”‚
       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Scraper (Railway)           â”‚
       â”‚   â”œâ”€ Betano                   â”‚
       â”‚   â”œâ”€ Bet365                   â”‚
       â”‚   â”œâ”€ Superbet                 â”‚
       â”‚   â””â”€ EsportesDaSorte          â”‚
       â”‚   â””â”€ Port: 8000               â”‚
       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ (retorna dados para)
            â”‚
       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Backend armazena no DB      â”‚
       â”‚   e notifica Telegram         â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Testar Localmente Primeiro

### 1. Com Docker Compose

```bash
# Terminal 1: Inicia todos os serviÃ§os
docker-compose up

# Terminal 2: Trigger manualmente
curl -X POST http://localhost:8000/api/trigger/all
```

### 2. Verificar logs

```bash
# Logs do scraper
docker-compose logs -f scraper

# Logs do backend
docker-compose logs -f api

# Logs do banco
docker-compose logs -f postgres
```

### 3. Testar scraper diretamente

```bash
# Acessa scraper direto
curl -X POST http://localhost:8001/scrape/betano

# Resposta esperada:
{
  "source": "betano",
  "items": 25,
  "data": [...]
}
```

---

## âš ï¸ Pontos CrÃ­ticos para ProduÃ§Ã£o

### 1. **Timeout das RequisiÃ§Ãµes**
- Scrapers podem levar **60-120 segundos**
- Configure timeout de pelo menos **300 segundos** no N8N
- Use **background tasks** para nÃ£o bloquear a API

### 2. **Rate Limiting**
- Sites podem bloquear por muitas requisiÃ§Ãµes
- Use proxies (jÃ¡ configurado com 10 IPs)
- Implemente delay entre scrapers

### 3. **Monitoramento**
- Verifique logs regularmente no Railway
- Configure alertas para falhas de scraper
- Monitore uso de banda e CPU

### 4. **Dados Duplicados**
- Implemente dedup por `(event_id, bookmaker, timestamp)`
- Atualize em vez de inserir registros duplicados

### 5. **Limpeza de Dados**
```bash
# Remover eventos com mais de 7 dias
curl -X DELETE http://seu-backend/api/events/cleanup?days_old=7
```

---

## ğŸ“Š VariÃ¡veis de Ambiente Recomendadas

Para Railway, adicione essas variÃ¡veis:

```env
# Database
DATABASE_URL=postgresql://...

# Telegram
TELEGRAM_BOT_TOKEN=...
TELEGRAM_CHAT_ID=...

# Scraper
SCRAPER_API_URL=https://seu-scraper-railway.railway.app
SCRAPER_TIMEOUT=300

# Proxies
IP_1=...
IP_2=...
# ... atÃ© IP_10

# Logging
LOG_LEVEL=info
```

---

## ğŸš€ Deploy RÃ¡pido

### 1. Crie dois serviÃ§os no Railway

```bash
# Railway CLI
railway service create backend
railway service create scraper
railway service create postgres
```

### 2. Aponte para os Dockerfiles

```
Backend â†’ ./backend/Dockerfile
Scraper â†’ ./scrapers/dockerfile
Postgres â†’ image: postgres:16-alpine
```

### 3. Configure variÃ¡veis

```
Backend: DATABASE_URL, TELEGRAM_BOT_TOKEN, SCRAPER_API_URL
Scraper: SCRAPER_TIMEOUT, IP_1...IP_10
Postgres: POSTGRES_PASSWORD, POSTGRES_DB
```

### 4. Configure N8N para chamar Backend

```
POST https://seu-backend-railway.railway.app/api/trigger/all
```

**Pronto! ğŸ‰**

---

## ğŸ“ Troubleshooting

| Problema | SoluÃ§Ã£o |
|----------|---------|
| Timeout apÃ³s 30s | Aumentar timeout no N8N, usar background tasks |
| Scraper retorna erro 500 | Verificar logs: `railway logs --service scraper` |
| Dados nÃ£o salvam no DB | Verificar DATABASE_URL e credenciais |
| Bot nÃ£o envia notificaÃ§Ã£o | Verificar TELEGRAM_BOT_TOKEN e CHAT_ID |
| Proxy bloqueando | Trocar IP ou desativar proxy (comentar em proxy_manager.py) |

---

## ğŸ¯ Resumo das 3 OpÃ§Ãµes

| OpÃ§Ã£o | Melhor Para | Complexidade | Reliability |
|-------|-------------|--------------|-------------|
| **1. N8N â†’ Backend â†’ Scraper** | ProduÃ§Ã£o | â­â­â­ | â­â­â­â­â­ |
| **2. N8N â†’ Scraper direto** | Testes | â­â­ | â­â­ |
| **3. cURL manual** | Debug | â­ | â­ |

**RecomendaÃ§Ã£o: Use a OPÃ‡ÃƒO 1 para Railway!** âœ…
