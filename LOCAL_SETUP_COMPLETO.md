# ğŸ  Sistema de Scrapers Locais - Guia Completo

## ğŸ¯ VisÃ£o Geral

Sistema completo para coletar odds de casas de apostas **usando sua internet local (sem proxy)** e enviar os dados para a API no Railway.

## ğŸ“¦ Componentes

### 1. Scrapers Locais (Python)
- **Betano**: âœ… Funcional
- **Esportes da Sorte**: âœ… Funcional  
- **Superbet**: âš ï¸ Em desenvolvimento
- **Bet365**: âš ï¸ Em desenvolvimento

### 2. API Local (FastAPI)
- Endpoint: `http://localhost:8000/api/trigger/local`
- Executa todos os scrapers e retorna JSON
- Envia dados para Railway automÃ¡ticamente

### 3. n8n Workflows
- **Manual**: ExecuÃ§Ã£o sob demanda
- **AutomÃ¡tico**: Cron (a cada 2h entre 10h-21h)

## ğŸš€ Como Usar

### OpÃ§Ã£o 1: Via Docker (Recomendado)

```powershell
# 1. Configure o .env.local
# Edite e adicione a URL da sua API no Railway
API_URL=https://seu-projeto.up.railway.app/api/odds/scraper

# 2. Suba os containers
docker compose up -d

# 3. Acesse o n8n
# http://localhost:5679

# 4. Importe os workflows
# VÃ¡ em Workflows â†’ Import from File
# Importe: n8n/workflows/Scraper Local Manual.json
# Importe: n8n/workflows/Scraper Local Automation.json

# 5. Teste manualmente primeiro
# Abra "Scraper Local Manual" e clique em "Execute Workflow"

# 6. Ative o automÃ¡tico
# Abra "Scraper Local Automation" e ative o toggle
```

### OpÃ§Ã£o 2: Diretamente com Python

```powershell
# 1. Instale dependÃªncias
pip install -r requirements.txt
playwright install chromium

# 2. Configure o .env.local
API_URL=https://seu-projeto.up.railway.app/api/odds/scraper

# 3. Execute
python scrapers\local\run_all_local.py

# Ou no Windows
run_local_scraper.bat
```

### OpÃ§Ã£o 3: Via API HTTP

```powershell
# Se a API local estiver rodando em http://localhost:8000
curl.exe -X POST http://localhost:8000/api/trigger/local

# Ou
Invoke-RestMethod -Uri "http://localhost:8000/api/trigger/local" -Method Post
```

## ğŸ”„ Fluxo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   n8n Trigger   â”‚  â° Cron: A cada 2h
â”‚  (10h-21h)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    HTTP POST Request    â”‚
â”‚ /api/trigger/local      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Local (FastAPI)   â”‚  ğŸ Container scraper-local
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â†’ Betano Local Scraper      âœ… Coleta dados
         â”œâ”€â†’ Superbet Local Scraper    âš ï¸ Parser pendente
         â”œâ”€â†’ Esportes Local Scraper    âœ… Coleta dados
         â””â”€â†’ Bet365 Local Scraper      âš ï¸ Parser pendente
                    â”‚
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Formata dados      â”‚
         â”‚  (formato padrÃ£o)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   POST para Railway â”‚  â˜ï¸ /api/odds/scraper
         â”‚   (send_odds_to_api)â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  PostgreSQL Railway â”‚  ğŸ’¾ Salva no banco
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   n8n processa      â”‚  ğŸ“Š Formata resultado
         â”‚   resposta JSON     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Estrutura de Resposta da API

```json
{
  "triggered_at": "2026-02-11T18:30:00.000Z",
  "environment": "local",
  "proxy_enabled": false,
  "status": "success",
  "total_items": 13,
  "scrapers": {
    "betano": {
      "status": "success",
      "items": 8,
      "sent_to_api": true
    },
    "superbet": {
      "status": "warning",
      "items": 0,
      "message": "Nenhum dado coletado (parser pendente)"
    },
    "esportesdasorte": {
      "status": "success",
      "items": 5,
      "sent_to_api": true
    },
    "bet365": {
      "status": "warning",
      "items": 0,
      "message": "Nenhum dado coletado (parser pendente)"
    }
  }
}
```

## ğŸ³ Containers Docker

| Container | Porta | DescriÃ§Ã£o |
|-----------|-------|-----------|
| `leite-bets-local-scraper` | 8000 | API FastAPI com scrapers |
| `leite-bets-local-n8n` | 5679 | n8n para automaÃ§Ã£o |

```powershell
# Ver containers rodando
docker ps

# Ver logs do scraper
docker logs leite-bets-local-scraper

# Ver logs do n8n
docker logs leite-bets-local-n8n

# Parar tudo
docker compose down

# Rebuildar e reiniciar
docker compose up -d --build
```

## â° Agendamento

**Cron padrÃ£o:** `0 10-21/2 * * *`

**ExecuÃ§Ãµes:**
- 10:00
- 12:00
- 14:00
- 16:00
- 18:00
- 20:00

**Modificar horÃ¡rio:**
1. Abra o workflow no n8n
2. Clique em "Schedule Trigger Local"
3. Modifique "Cron Expression"
4. Salve

**Exemplos:**
- `0 */3 * * *` - A cada 3 horas
- `0 8,12,16,20 * * *` - Ã€s 8h, 12h, 16h e 20h
- `0 0 * * *` - Uma vez por dia (meia-noite)

## ğŸ” Monitoramento

### Logs do Python

```powershell
# Container
docker logs leite-bets-local-scraper -f

# Script direto
python scrapers\local\run_all_local.py
```

### Logs do n8n

```
http://localhost:5679
â†’ Executions
â†’ Selecione uma execuÃ§Ã£o
â†’ Veja detalhes de cada node
```

### Verificar API

```powershell
# Health check
curl http://localhost:8000/health

# Testar endpoint local
curl -X POST http://localhost:8000/api/trigger/local
```

## ğŸ†š ComparaÃ§Ã£o: Local vs Railway

| Aspecto | Scrapers Locais | Scrapers Railway |
|---------|----------------|------------------|
| **Proxy** | âŒ NÃ£o usa | âœ… Webshare residencial |
| **Internet** | Sua conexÃ£o | Proxy rotativo |
| **Velocidade** | âš¡ Mais rÃ¡pido | ğŸ¢ Pode ser lento |
| **Custo** | ğŸ’° GrÃ¡tis | ğŸ’³ ~$5-10/mÃªs (proxy) |
| **Bloqueios** | âš ï¸ Risco maior | âœ… Risco menor |
| **Uso** | ğŸ  Dev/teste local | â˜ï¸ ProduÃ§Ã£o |
| **ExecuÃ§Ã£o** | ğŸ–¥ï¸ Sua mÃ¡quina | â˜ï¸ Nuvem 24/7 |

## âš ï¸ LimitaÃ§Ãµes

1. **Bloqueios de IP**: Sites podem bloquear se fazer muitas requisiÃ§Ãµes
2. **GeolocalizaÃ§Ã£o**: Alguns sites exigem IP brasileiro
3. **Velocidade**: Depende da sua internet
4. **Disponibilidade**: SÃ³ funciona se sua mÃ¡quina estiver ligada

## ğŸ’¡ Dicas

1. **NÃ£o abuse**: Rode no mÃ¡ximo a cada 2-4 horas
2. **Use VPN BR**: Se estiver fora do Brasil
3. **Monitore logs**: Para detectar bloqueios cedo
4. **Teste manual**: Antes de ativar o automÃ¡tico
5. **HorÃ¡rio**: Rode em horÃ¡rios de baixo trÃ¡fego (10h-21h)

## ğŸ› Troubleshooting

### âŒ "Connection refused" ao chamar API

**Causa**: Container nÃ£o estÃ¡ rodando  
**SoluÃ§Ã£o**:
```powershell
docker ps
docker logs leite-bets-local-scraper
docker compose restart scraper-local
```

### âŒ "API_URL nÃ£o configurada"

**Causa**: `.env.local` nÃ£o tem `API_URL`  
**SoluÃ§Ã£o**:
```powershell
# Edite .env.local e adicione:
API_URL=https://seu-projeto.up.railway.app/api/odds/scraper

# Reinicie container
docker compose restart scraper-local
```

### âŒ "Timeout" ao coletar

**Causa**: Site demorou muito ou bloqueou  
**SoluÃ§Ã£o**:
- Aguarde algumas horas
- Use VPN
- Aumente timeout (180s padrÃ£o)

### âŒ Workflow nÃ£o executa automaticamente

**VerificaÃ§Ãµes**:
1. Workflow estÃ¡ ativo? (toggle verde)
2. Container n8n estÃ¡ rodando?
3. ExpressÃ£o cron estÃ¡ correta?

```powershell
docker ps | Select-String "n8n"
docker logs leite-bets-local-n8n
```

### âš ï¸ Dados nÃ£o chegam no Railway

**VerificaÃ§Ãµes**:
1. `API_URL` estÃ¡ correta?
2. Railway estÃ¡ acessÃ­vel?
3. Logs mostram "sent_to_api: true"?

```powershell
# Teste a URL manualmente
curl https://seu-projeto.up.railway.app/health

# Veja logs do scraper
docker logs leite-bets-local-scraper | Select-String "enviado"
```

## ğŸ“š Arquivos Importantes

```
leite-bets/
â”œâ”€â”€ .env.local                          # âš™ï¸ ConfiguraÃ§Ãµes
â”œâ”€â”€ docker-compose.yml                  # ğŸ³ Containers
â”œâ”€â”€ run_local_scraper.bat               # ğŸªŸ Script Windows
â”œâ”€â”€ QUICK_START_LOCAL.md                # ğŸš€ Guia rÃ¡pido
â”‚
â”œâ”€â”€ scrapers/local/                     # ğŸ  Scrapers sem proxy
â”‚   â”œâ”€â”€ browser_no_proxy.py
â”‚   â”œâ”€â”€ betano_local.py
â”‚   â”œâ”€â”€ superbet_local.py
â”‚   â”œâ”€â”€ esportesdasorte_local.py
â”‚   â”œâ”€â”€ bet365_local.py
â”‚   â”œâ”€â”€ run_all_local.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ scrapers/api/
â”‚   â””â”€â”€ routes.py                       # ğŸŒ Novo endpoint /api/trigger/local
â”‚
â””â”€â”€ n8n/workflows/
    â”œâ”€â”€ Scraper Local Manual.json       # ğŸ–±ï¸ ExecuÃ§Ã£o manual
    â”œâ”€â”€ Scraper Local Automation.json   # â° AutomÃ¡tico (cron)
    â”œâ”€â”€ README.md                       # ğŸ“– Docs workflows
    â””â”€â”€ IMPORTAR.md                     # ğŸ“¥ Guia importaÃ§Ã£o
```

## âœ… Checklist Final

- [ ] `.env.local` configurado com `API_URL`
- [ ] Containers rodando: `docker ps`
- [ ] n8n acessÃ­vel: http://localhost:5679
- [ ] Workflows importados no n8n
- [ ] Teste manual executou com sucesso
- [ ] API Railway estÃ¡ acessÃ­vel
- [ ] Logs mostram "jogos coletados"
- [ ] Dados chegaram no Railway
- [ ] Workflow automÃ¡tico ativado
- [ ] Monitoramento configurado

## ğŸ¯ PrÃ³ximos Passos

1. âœ… Complete a configuraÃ§Ã£o (`API_URL`)
2. âœ… Teste com workflow manual
3. âœ… Verifique dados no Railway
4. âœ… Ative workflow automÃ¡tico
5. âœ… Monitore primeiras execuÃ§Ãµes
6. âš ï¸ Implemente parsers Superbet/Bet365
7. ğŸ“§ Configure notificaÃ§Ãµes (Telegram/Email)
8. ğŸ“Š Crie dashboard de monitoramento

## ğŸ“ Suporte

- **Logs**: Sempre comece pelos logs
- **API**: Teste endpoints manualmente
- **n8n**: Use execuÃ§Ãµes manuais para debug
- **Docs**: Leia READMEs especÃ­ficos de cada mÃ³dulo

---

**ğŸ† Agora vocÃª tem um sistema completo de coleta de odds rodando localmente, enviando dados para a nuvem, tudo automatizado!**
